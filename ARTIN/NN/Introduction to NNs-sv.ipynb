{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks \n",
    "\n",
    "\n",
    "** Ecole Centrale Nantes **\n",
    "\n",
    "** Diana Mateus **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Participants : **\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General description\n",
    "In this lab we will create a simple classifier based on neural networks. We will progress in two parts:\n",
    "- In the first part, and to better understand the involved operations, we will create a single-neuron model and optimize its parameters \"by hand\". For this first part we will only use the **Numpy** library\n",
    "- We will then build a multi-layer perceptron with the built-in library **Keras** module and **tensorflow**. Tensorflow is already installed in the university computers. If using your own computer you should have already installed **tensorflow** or use **collab** online platform.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "Start by runing the following lines to load and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('dataset/train_catvnoncat.h5', \"r\")\n",
    "    train_x = np.array(train_dataset[\"train_set_x\"][:]) \n",
    "    train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
    "    test_dataset = h5py.File('dataset/test_catvnoncat.h5', \"r\")\n",
    "    test_x = np.array(test_dataset[\"test_set_x\"][:]) \n",
    "    test_y = np.array(test_dataset[\"test_set_y\"][:])\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) \n",
    "    \n",
    "    train_y = train_y.reshape((1, train_y.shape[0]))\n",
    "    test_y = test_y.reshape((1, test_y.shape[0]))\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, classes\n",
    "\n",
    "train_x, train_y, test_x, test_y, classes=load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (209, 64, 64, 3)\n",
      "We have 209 images of dimensionality 64x64x3\n"
     ]
    }
   ],
   "source": [
    "# run several times to visualize different data points\n",
    "# the title shows the ground truth class labels (0=no cat , 1 = cat)\n",
    "index = np.random.randint(low=0,high=train_y.shape[1])\n",
    "plt.imshow(train_x[index])\n",
    "plt.title(\"Image \"+str(index)+\" label \"+str(train_y[0,index]))\n",
    "plt.show()\n",
    "print (\"Train X shape: \" + str(train_x.shape))\n",
    "print (\"We have \"+str(train_x.shape[0]), \n",
    "       \"images of dimensionality \" \n",
    "       + str(train_x.shape[1])+ \"x\"\n",
    "       + str(train_x.shape[2])+ \"x\"\n",
    "       + str(train_x.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "In the following lines we vectorize the images (Instead of a 2-D image we will give as input to the models a 1-D vector). The normalization makes the image intensities be between 0 and 1, and converts the images to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (12288, 209)\n",
      "Train Y shape: (1, 209)\n",
      "Test X shape: (12288, 50)\n",
      "Test Y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data\n",
    "train_x = train_x.reshape(train_x.shape[0], -1).T\n",
    "test_x = test_x.reshape(test_x.shape[0], -1).T\n",
    "print (\"Train X shape: \" + str(train_x.shape))\n",
    "print (\"Train Y shape: \" + str(train_y.shape))\n",
    "print (\"Test X shape: \" + str(test_x.shape))\n",
    "print (\"Test Y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 209)\n"
     ]
    }
   ],
   "source": [
    "val_X = train_x[:round(len(train_x[1])*0.1)]\n",
    "print(val_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_x = train_x/255.\n",
    "test_x = test_x/255.\n",
    "# print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification with a single neuron \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Fill-in the following three functions to define the single neuron model:\n",
    "- A function **initialize_parameters** that randomly initializes the model's weights with small values. The number of the weights corresponds to the dimension of the input (size of the image)\n",
    "- A function **sigmoid** that computes the sigmoid activation function\n",
    "- A function **neuron** that given an input vector, weights and biases computes the output of the single neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(dim):\n",
    "    w = np.random.randn(dim)*0.01\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron(w,b,X):\n",
    "    pred_y = sigmoid(np.dot(w.T, X) + b)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** **Forward Pass:**\n",
    "Use the three functions above to compute a first forward pass for the input matrix $X$ containing the loaded dataset, for some initialization of the weights and bias.\n",
    " \n",
    " \\begin{align}\n",
    " Y_{\\rm pred}=\\sigma(w^\\top X+b) = [y_{\\rm pred}^{(1)},y_{\\rm pred}^{(2)},\\dots,y_{\\rm pred}^{(m)}]\n",
    " \\end{align}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5362462  0.57299473 0.56561698 0.42687221 0.45039509 0.59240764\n",
      " 0.50197812 0.57859752 0.51898787 0.61827116 0.56047198 0.48565279\n",
      " 0.56347742 0.51324357 0.44915495 0.6649728  0.72975563 0.66634311\n",
      " 0.57361426 0.68307831 0.50930585 0.40588886 0.63509182 0.69053831\n",
      " 0.54733422 0.51262222 0.52270725 0.45766053 0.45824264 0.46610539\n",
      " 0.43327512 0.57110452 0.77141204 0.51830295 0.4635967  0.58511973\n",
      " 0.45745554 0.71190345 0.49898059 0.53607347 0.58599047 0.42522662\n",
      " 0.69643518 0.59710535 0.55035154 0.59875242 0.6086452  0.58598357\n",
      " 0.44261737 0.54379556 0.62372353 0.47303897 0.55849447 0.63373467\n",
      " 0.55171192 0.67651641 0.51919757 0.6051944  0.53323032 0.51767392\n",
      " 0.57488694 0.61995094 0.57807818 0.54109587 0.60722665 0.5582882\n",
      " 0.66569835 0.59657143 0.61211611 0.74176636 0.73800365 0.53655272\n",
      " 0.4608692  0.46385266 0.44916732 0.59587872 0.52298712 0.58856748\n",
      " 0.53648995 0.5372238  0.49396223 0.56384384 0.57370164 0.5807119\n",
      " 0.62779864 0.48196267 0.63162193 0.52402179 0.61272561 0.51938628\n",
      " 0.55569671 0.53683607 0.46895872 0.61002731 0.67015636 0.50651576\n",
      " 0.64851658 0.52010822 0.51198124 0.58125373 0.73849859 0.50493528\n",
      " 0.44549821 0.54047074 0.5908871  0.56673444 0.54141749 0.65654355\n",
      " 0.59833274 0.52058524 0.51092122 0.57989951 0.5007346  0.47481058\n",
      " 0.56389573 0.54259589 0.69839871 0.52452497 0.55811804 0.63652269\n",
      " 0.56780965 0.63569833 0.43674669 0.42730218 0.56241459 0.56434943\n",
      " 0.52841146 0.54864077 0.56407726 0.52729548 0.53269001 0.53495158\n",
      " 0.55012591 0.53760119 0.63153541 0.51866615 0.55929906 0.63366871\n",
      " 0.48428589 0.63448595 0.38686484 0.62801684 0.70808346 0.50315028\n",
      " 0.51821456 0.57179904 0.6571639  0.66371608 0.49935363 0.64532303\n",
      " 0.64220623 0.52458311 0.45845052 0.75912836 0.53853238 0.52231932\n",
      " 0.53464714 0.48034157 0.5937874  0.59252674 0.53453164 0.63702649\n",
      " 0.6522251  0.5630263  0.6061504  0.45786198 0.62895397 0.56085439\n",
      " 0.53346656 0.67595587 0.74401967 0.57421238 0.59028229 0.5172209\n",
      " 0.57710145 0.5074207  0.48929883 0.55678259 0.54659354 0.5784724\n",
      " 0.65335115 0.50966891 0.56322943 0.54022668 0.55688229 0.55908593\n",
      " 0.47162762 0.52789514 0.70576735 0.51928838 0.56389786 0.68708052\n",
      " 0.68794819 0.69875835 0.52140459 0.56004129 0.5324871  0.50376924\n",
      " 0.51299887 0.5254835  0.58183537 0.7506511  0.6076193  0.57698428\n",
      " 0.5292581  0.49092822 0.66990485 0.49907181 0.53055601]\n"
     ]
    }
   ],
   "source": [
    "w_ini, b_ini = initialize_parameters(train_x.shape[0])\n",
    "pred_y = neuron(w_ini, b_ini, train_x)\n",
    "\n",
    "# print(len(pred_y))\n",
    "# w_ini\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Cost estimation:**\n",
    " \n",
    "We will use a binary cross-entropy loss, so that the empirical risk can be computed as:\n",
    " \\begin{align}\n",
    " E = - \\frac{1}{m} \\sum_{i=1}^m \n",
    " y^{(i)} \\log(y_{\\rm pred}^{(i)}) +\n",
    " (1-y^{(i)}) \\log(1-y_{\\rm pred}^{(i)})\n",
    " \\end{align}\n",
    " \n",
    " The following cross-entropy function should give as result the scalar cost value computed over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.21925706366648"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crossentropy(Y,Ypred):\n",
    "    \n",
    "    m = len(Y)\n",
    "    Y = np.squeeze(Y)\n",
    "    cost = -(1/m) * np.sum(Y*np.log2(Ypred) + (1 - Y)*(np.log2(1 - Ypred)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "crossentropy(train_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Back propagation:**\n",
    "\n",
    "After initializing the parameters and doing a forward pass, we need to backpropagate the cost by computing the gradient with respect to the model parameters to later update the weights\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w} = & \\frac{1}{m} X(Y_{\\rm pred}-Y)^T\\\\\n",
    "\\frac{\\partial E}{\\partial b} = & \\frac{1}{m} \\sum{(Y_{\\rm pred}-Y)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "See a demonstration of how the gradient was computed in \n",
    "https://en.wikipedia.org/wiki/Cross_entropy\n",
    "\n",
    "Fill-in the backpropagation function which receives as input the the training set (X,Y), as well as the current predictions and returns the gradients updates for the weights and bias\n",
    "\n",
    "Hint: When the error is computed for several samples simultaneously, the gradient is averaged over the contribution of different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(X, Y, Ypred):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    #find gradient (back propagation)\n",
    "    dw = np.dot(X, (Ypred - Y).T)/m\n",
    "    db = np.sum((Ypred - Y))/m\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db} \n",
    "    \n",
    "    return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = backpropagate(train_x, train_y, pred_y)\n",
    "len(grads['dw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Optimization**\n",
    "After initializing the parameters, computing the cost function, and calculating gradients, we can now update the parameters using gradient descent. Use the functions implemented above to fill_in the \"gradient_descent\" function that optimizes the parameters given a training set X, Y, a fixed number of iterations, and a learning_rate. Store and plot the value of the loss function at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 201.163125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ananconda\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log2\n",
      "  \"\"\"\n",
      "E:\\ananconda\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 100: 35882577.260656\n",
      "Cost after iteration 200: 6685129.372667\n",
      "Cost after iteration 300: 24339949.844052\n",
      "Cost after iteration 400: 23915981.384334\n",
      "Cost after iteration 500: 36178559.138554\n",
      "Cost after iteration 600: 17453598.272085\n",
      "Cost after iteration 700: 4062289.104061\n",
      "Cost after iteration 800: 4717262.523399\n",
      "Cost after iteration 900: 19665876.797896\n",
      "Cost after iteration 1000: 19068272.120410\n",
      "Cost after iteration 1100: 25507087.485591\n",
      "Cost after iteration 1200: 9714758.938192\n",
      "Cost after iteration 1300: 16384080.988804\n",
      "Cost after iteration 1400: 3643848.135214\n",
      "Cost after iteration 1500: 21791181.054545\n",
      "Cost after iteration 1600: 11656886.145915\n",
      "Cost after iteration 1700: 8514143.583714\n",
      "Cost after iteration 1800: 27968401.056661\n",
      "Cost after iteration 1900: 9806645.464962\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(X, Y, iterations, learning_rate):\n",
    "    costs = []\n",
    "    w, b = initialize_parameters(train_x.shape[0])\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        Ypred = neuron(w, b, X)\n",
    "        cost = crossentropy(Y, Ypred)\n",
    "        grads= backpropagate(X, Y, Ypred)\n",
    "        \n",
    "        #update parameters\n",
    "        w = w - grads['dw']*learning_rate\n",
    "        b = b - grads['db']*learning_rate\n",
    "        costs.append(cost)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "       \n",
    "    return w,b, costs\n",
    "\n",
    "w, b, costs = gradient_descent(train_x,train_y,iterations=2000, learning_rate = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Plot the training curve**\n",
    "Plot the evolution of the cost vs the iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Prediction**\n",
    "Use the optimized parameters to make predictions both for the train and test sets and compute the accuracy for each. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):    \n",
    "    y_pred = np.round(sigmoid(np.dot(w.T, X) + b))\n",
    "    return y_pred\n",
    "\n",
    "# predict\n",
    "\n",
    "print(b.shape)\n",
    "\n",
    "train_pred_y = predict(w, b, train_x)\n",
    "test_pred_y = predict(w, b, test_x)\n",
    "\n",
    "print(\"Train Acc: {} %\".format(100 - np.mean(np.abs(train_pred_y - train_y)) * 100))\n",
    "print(\"Test Acc: {} %\".format(100 - np.mean(np.abs(test_pred_y - test_y)) * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Early stopping** \n",
    "- Adapt the gradient descent function to consider part (a percentage) of the training data for validation. Use the validation set to choose the training hyperparameters (learning_rate, iterations). \n",
    "- Plot the training and validation curves\n",
    "- Report again the training and test accuracy and loss for the new trained model\n",
    "- What do you observe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_early_stopping(X, Y, iterations, learning_rate, percentage=.1):\n",
    "    \n",
    "    return best_w,best_b,train_costs,val_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CNNs with Keras\n",
    "\n",
    "Adapt the example in this website https://keras.io/examples/vision/mnist_convnet/ to our problem. To this end:\n",
    "- change the number of classes and the input size\n",
    "- remove the expand_dims(x_train, -1): it is not necessary to expand the dimensions since our input is 3-dimensional \n",
    "- you may need to transpose the labels vector\n",
    "- change the categorical cross-entropy to the binary cross entropy given that our problem is binary classification. \n",
    "- also change the softmax to sigmoid, the more appropriate activation function for binary data\n",
    "\n",
    "We can choose a single neuron output passed through sigmoid, and then set a threshold to choose the class, or use two neuron output and then perform a softmax.\n",
    "\n",
    "**2.1** Can you get the accuracy better than in our hand single-neuron model?Try different configurations and explain the changes you have made.\n",
    "\n",
    "**2.2** Compute the train and test loss and accuracy after the model has been trained.  What model parameters does the ``fit`` function retain?\n",
    "\n",
    "**2.3** How many parameters does the network have, explain where the number comes from.\n",
    "\n",
    "**2.4** What is the receptive field of the network https://distill.pub/2019/computing-receptive-fields/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('dataset/train_catvnoncat.h5', \"r\")\n",
    "    train_x = np.array(train_dataset[\"train_set_x\"][:]) \n",
    "    train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
    "    test_dataset = h5py.File('dataset/test_catvnoncat.h5', \"r\")\n",
    "    test_x = np.array(test_dataset[\"test_set_x\"][:]) \n",
    "    test_y = np.array(test_dataset[\"test_set_y\"][:])\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) \n",
    "    \n",
    "    train_y = train_y.reshape((1, train_y.shape[0]))\n",
    "    test_y = test_y.reshape((1, test_y.shape[0]))\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, classes\n",
    "\n",
    "train_x, train_y, test_x, test_y, classes=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "x_train, y_train, x_test, y_test, classes=load_dataset()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 25090     \n",
      "=================================================================\n",
      "Total params: 53,730\n",
      "Trainable params: 53,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "input_shape = x_train.shape[1:] # resize the input shape\n",
    "#print(input_shape)\n",
    "num_classes = 2\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train.T) # change the input shape to each image 3 dims\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) # code the target\n",
    "\n",
    "y_test = np.squeeze(y_test.T) # change the shape\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes) # code the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188 samples, validate on 21 samples\n",
      "Epoch 1/15\n",
      "188/188 [==============================] - 3s 15ms/sample - loss: 0.6663 - accuracy: 0.5691 - val_loss: 0.5237 - val_accuracy: 0.8095\n",
      "Epoch 2/15\n",
      "188/188 [==============================] - 0s 487us/sample - loss: 0.7327 - accuracy: 0.6383 - val_loss: 0.5483 - val_accuracy: 0.8095\n",
      "Epoch 3/15\n",
      "188/188 [==============================] - 0s 488us/sample - loss: 0.6335 - accuracy: 0.6383 - val_loss: 0.5938 - val_accuracy: 0.8095\n",
      "Epoch 4/15\n",
      "188/188 [==============================] - 0s 488us/sample - loss: 0.6274 - accuracy: 0.6383 - val_loss: 0.5436 - val_accuracy: 0.8095\n",
      "Epoch 5/15\n",
      "188/188 [==============================] - 0s 504us/sample - loss: 0.5923 - accuracy: 0.6383 - val_loss: 0.4995 - val_accuracy: 0.8095\n",
      "Epoch 6/15\n",
      "188/188 [==============================] - 0s 483us/sample - loss: 0.5986 - accuracy: 0.6383 - val_loss: 0.5061 - val_accuracy: 0.8095\n",
      "Epoch 7/15\n",
      "188/188 [==============================] - 0s 495us/sample - loss: 0.5426 - accuracy: 0.6383 - val_loss: 0.5185 - val_accuracy: 0.8095\n",
      "Epoch 8/15\n",
      "188/188 [==============================] - 0s 509us/sample - loss: 0.5331 - accuracy: 0.6436 - val_loss: 0.5023 - val_accuracy: 0.8095\n",
      "Epoch 9/15\n",
      "188/188 [==============================] - 0s 477us/sample - loss: 0.5067 - accuracy: 0.6436 - val_loss: 0.5162 - val_accuracy: 0.8095\n",
      "Epoch 10/15\n",
      "188/188 [==============================] - 0s 493us/sample - loss: 0.5145 - accuracy: 0.6383 - val_loss: 0.5108 - val_accuracy: 0.8095\n",
      "Epoch 11/15\n",
      "188/188 [==============================] - 0s 504us/sample - loss: 0.4833 - accuracy: 0.6516 - val_loss: 0.5130 - val_accuracy: 0.7143\n",
      "Epoch 12/15\n",
      "188/188 [==============================] - 0s 488us/sample - loss: 0.4658 - accuracy: 0.7606 - val_loss: 0.5263 - val_accuracy: 0.7143\n",
      "Epoch 13/15\n",
      "188/188 [==============================] - 0s 494us/sample - loss: 0.4398 - accuracy: 0.7606 - val_loss: 0.5626 - val_accuracy: 0.8095\n",
      "Epoch 14/15\n",
      "188/188 [==============================] - 0s 508us/sample - loss: 0.4298 - accuracy: 0.7420 - val_loss: 0.5787 - val_accuracy: 0.8095\n",
      "Epoch 15/15\n",
      "188/188 [==============================] - 0s 493us/sample - loss: 0.4003 - accuracy: 0.8191 - val_loss: 0.6122 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e1e4beb240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comiple and fit\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: \n",
    "Replace the fit function by your own tensorflow  implementation\n",
    "\n",
    "1. Instantiate one of keras.optimizers to train the model.\n",
    "\n",
    "optimizer = \n",
    "\n",
    "2. Instantiate a loss from keras.losses\n",
    "\n",
    "loss_fn = \n",
    "\n",
    "3. Prepare the metrics. Instatiate the metrics from keras.metrics\n",
    "\n",
    "train_acc_metric =\n",
    "val_acc_metric =\n",
    "\n",
    "4. Stochastic Gradient Loop\n",
    "    * Iterate over the dataset in batches with \n",
    "    * Open a GradientTape() scope \n",
    "    * Inside this scope call the model (forward pass)\n",
    "    * Compute the loss outside the scope\n",
    "    * Retrieve the weight gradients\n",
    "    * Use the optimimzer to update the weights with the gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own tensorflow implementation\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean('train_loss')\n",
    "train_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "epoch_loss_avg_test = tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images)\n",
    "        loss_step = loss_fn(labels, pred)\n",
    "    grads = t.gradient(loss_step, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    epoch_loss_avg(loss_step)\n",
    "    train_accuracy(labels, tf.cast(pred > 0.5, tf.int32))\n",
    "\n",
    "def test_step(model ,images,labels):\n",
    "    pred = model.predict(images)\n",
    "    loss_step = loss_fn(labels, pred)\n",
    "    epoch_loss_avg_test(loss_step)\n",
    "    test_accuracy(labels,tf.cast(pred > 0.5, tf.int32))\n",
    "\n",
    "\n",
    "train_loss_results = []\n",
    "train_acc_results = []\n",
    "\n",
    "test_loss_results = []\n",
    "test_acc_results = []\n",
    "\n",
    "num_epochs = 60\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test, classes=load_dataset()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "y_train = np.squeeze(y_train.T) # change the input shape to each image 3 dims\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) # code the target\n",
    "\n",
    "y_test = np.squeeze(y_test.T) # change the shape\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes) # code the target\n",
    "\n",
    "\n",
    "for each in range(num_epochs):\n",
    "    train_step(model, x_train, y_train)\n",
    "    print('.', end='')\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_acc_results.append(train_accuracy.result())\n",
    "        \n",
    "    test_step(model, x_test, y_test)\n",
    "    test_loss_results.append(epoch_loss_avg_test.result())\n",
    "    test_acc_results.append(test_accuracy.result())\n",
    "    print()\n",
    "    print('Epoch:{}:loss:{:.3f}, accuracy:{:.3f}, test_loss:{:.3f}, test_accuracy:{:.3f}'.format(\n",
    "        each+1,\n",
    "        epoch_loss_avg.result(),\n",
    "        train_accuracy.result(),\n",
    "        epoch_loss_avg_test.result(),\n",
    "        test_accuracy.result()\n",
    "    ))# print the result\n",
    "    epoch_loss_avg.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    epoch_loss_avg_test.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

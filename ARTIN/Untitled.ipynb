{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拟合效果不好 可能是网络深度不够 或者没有优化？\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "train_image_path = glob.glob('./data_set/dc_2000/train/*/*.jpg')\n",
    "# glob来提取 用*代表任意\n",
    "\n",
    "train_image_label = [int(p.split('\\\\')[1] == 'cat') for p in train_image_path]\n",
    "# 用列表推导式 int之后的true为1\n",
    "\n",
    "# print(train_image_label[:5],train_image_label[-5:])\n",
    "\n",
    "def load_preprosess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,channels=3) # 解码\n",
    "    image = tf.image.resize(image,[360,360])# 不规则的图像进行缩放\n",
    "    image = tf.image.random_crop(image,[256,256,3])#随机裁剪 写出通道数\n",
    "    image = tf.image.random_flip_left_right(image)#左右翻转\n",
    "    image = tf.image.random_flip_up_down(image)#上下翻转\n",
    "    #brightness contrast 也可以用来加强数据\n",
    "    image = tf.cast(image,tf.float32)# 转化数据类型\n",
    "    image = image/255# 归一化\n",
    "    label = tf.reshape(label,[1])\n",
    "    return image,label\n",
    "# tf.image.convert_image_dtype 如果原数据不是float转为float并做归一化\n",
    "\n",
    "#test上不做图片增强\n",
    "def load_preprosess_test_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,channels=3) # 解码\n",
    "    image = tf.image.resize(image,[256,256])# 不规则的图像进行缩放\n",
    "    image = tf.cast(image,tf.float32)# 转化数据类型\n",
    "    image = image/255# 归一化\n",
    "    label = tf.reshape(label,[1])\n",
    "    return image,label\n",
    "\n",
    "\n",
    "train_image_ds = tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label))\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#AUTUTUNE根据你的计算机自动使用并行运算\n",
    "#AUTOTUNE让计算机自己决定\n",
    "\n",
    "train_image_ds = train_image_ds.map(load_preprosess_image,num_parallel_calls=AUTOTUNE)\n",
    "#num_parallel_calls 是否用并行运算并选择个数\n",
    "#map把函数映射在集合上面\n",
    "#print(train_image_ds)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_count = len(train_image_path)\n",
    "train_image_ds = train_image_ds.shuffle(train_count).batch(BATCH_SIZE)\n",
    "train_image_ds = train_image_ds.prefetch(AUTOTUNE)\n",
    "#加快运行速度 提前读取下一批数据\n",
    "imgs , labels = next(iter(train_image_ds))\n",
    "#生成器迭代\n",
    "\n",
    "\n",
    "test_image_path = glob.glob('./data_set/dc_2000/test/*/*.jpg')\n",
    "#构建测试集\n",
    "test_image_label = [int(p.split('\\\\')[1] == 'cat') for p in test_image_path]\n",
    "test_image_ds = tf.data.Dataset.from_tensor_slices((test_image_path,test_image_label))\n",
    "test_image_ds = test_image_ds.map(load_preprosess_test_image() , num_parallel_calls=AUTOTUNE)\n",
    "test_image_ds = test_image_ds.batch(BATCH_SIZE)\n",
    "test_image_ds = test_image_ds.prefetch(AUTOTUNE)\n",
    "#提速\n",
    "\n",
    "#可以增加网络的深度和卷积的参数来提高拟合效果 增加宽度更容易出现过拟合效果 在Sequential模型下面每一层的卷积核不能太少\n",
    "#添加tf.keras.layers.BatchNormalization()正则化 防止过拟合 放在Conv2D后面\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),input_shape=(256,256,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    #减少参数\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    ")\n",
    "#没有训练\n",
    "\n",
    "pred = model(imgs)\n",
    "\n",
    "predict = np.array([p[0].numpy() for p in  tf.cast(pred>0,tf.int32)])\n",
    "real = np.array([l[0].numpy for l in labels])\n",
    "\n",
    "#自定义训练\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "#loss为可调用的参数\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean('train_loss')\n",
    "train_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "epoch_loss_avg_test = tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "def train_step(model,images,labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images)\n",
    "        loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels,pred)\n",
    "    grads = t.gradient(loss_step,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    epoch_loss_avg(loss_step)\n",
    "    train_accuracy(labels,tf.cast(pred > 0,tf.int32))\n",
    "\n",
    "def test_step(model ,images,labels):\n",
    "    pred = model.predict(images)\n",
    "    loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels,pred)\n",
    "    epoch_loss_avg_test(loss_step)\n",
    "    test_accuracy(labels,tf.cast(pred > 0, tf.int32))\n",
    "\n",
    "\n",
    "train_loss_results = []\n",
    "train_acc_results = []\n",
    "\n",
    "test_loss_results = []\n",
    "test_acc_results = []\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for each in range(num_epochs):\n",
    "    for imgs1,labels1 in train_image_ds:\n",
    "        train_step(model,imgs1,labels1)\n",
    "        print('.',end='')#显示一次训练完成\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_acc_results.append(train_accuracy.result())\n",
    "    for imgs_ , labels_ in test_image_ds:\n",
    "        test_step(model,imgs_,labels_)\n",
    "        test_loss_results.append(epoch_loss_avg_test.result())\n",
    "        test_acc_results.append(test_accuracy.result())\n",
    "    print()\n",
    "    print('Epoch:{}:loss:{:.3f}, accuracy:{:.3f}, test_loss:{:.3f}, test_accuracy:{:.3f}'.format(\n",
    "        each+1,\n",
    "        epoch_loss_avg.result(),\n",
    "        train_accuracy.result(),\n",
    "        epoch_loss_avg_test.result(),\n",
    "        test_accuracy.result()\n",
    "    ))#打印结果\n",
    "    epoch_loss_avg.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    epoch_loss_avg_test.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    #重置列表\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
